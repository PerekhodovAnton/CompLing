{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "092e5c0d",
      "metadata": {
        "id": "092e5c0d"
      },
      "source": [
        "# Домашнее задание  № 5. Матричные разложения/Тематическое моделирование"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f18446b7",
      "metadata": {
        "id": "f18446b7"
      },
      "source": [
        "### Задание № 1 (8 баллов)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf81eecc",
      "metadata": {
        "id": "cf81eecc"
      },
      "source": [
        "Попробуйте матричные разложения с 4 классификаторами - SGDClassifier, KNeighborsClassifier,  RandomForest, ExtraTreesClassifier (про него подробнее почитайте в документации, он похож на RF). Используйте и NMF, SVD и LDA. Сравните результаты на кросс-валидации и выберите лучшее сочетание.\n",
        "\n",
        "В итоге у вас должно получиться, как минимум 12 моделей (три разложения на каждый классификатор). Используйте 1 и те же параметры кросс-валидации. Параметры векторизации, параметры K в матричных разложениях, параметры классификаторов могут быть разными между экспериментами."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1760960",
      "metadata": {
        "id": "f1760960"
      },
      "source": [
        "Можете взять поменьше данных, если все будет обучаться слишком долго (не ставьте параметр K слишком большим в NMF и LDA, иначе точно будет слишком долго)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NLL1OgdE6JYB",
      "metadata": {
        "id": "NLL1OgdE6JYB"
      },
      "outputs": [],
      "source": [
        "!pip install gensim pymorphy2 seaborn pyLDAvis razdel numpy setuptools pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5e4fd78e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "9b84d8bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "9b84d8bd",
        "outputId": "ed51dad1-6a99-4df3-b94e-c9990ff6384d"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import pyLDAvis.gensim_models\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "from razdel import tokenize as razdel_tokenize\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML\n",
        "from sklearn.decomposition import TruncatedSVD, NMF, PCA, LatentDirichletAllocation\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "morph = MorphAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "283d4eb5",
      "metadata": {
        "id": "283d4eb5"
      },
      "outputs": [],
      "source": [
        "def normalize(text):\n",
        "    normalized_text = [word.text.strip(punctuation) for word \\\n",
        "                                                            in razdel_tokenize(text)]\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
        "    normalized_text = [morph.parse(word)[0].normal_form for word in normalized_text]\n",
        "    return ' '.join(normalized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "_QhHbb7b6ebF",
      "metadata": {
        "id": "_QhHbb7b6ebF"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('avito_category_classification.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "8gaMpK8L6g7G",
      "metadata": {
        "id": "8gaMpK8L6g7G"
      },
      "outputs": [],
      "source": [
        "data['description_norm'] = data['description'].apply(normalize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "c8bc0a73",
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_table(X, y, pipeline, N=6):\n",
        "    # измени ф-ю с семинара, чтобы выдавался только f1-mean, т.к. мне кажется,\n",
        "    # что по нему будет очень удобно выбрать лидирующее сочетание разложение+классификатор \n",
        "    labels = list(set(y))\n",
        "    fold_metrics = pd.DataFrame(index=labels)   \n",
        "    kfold = StratifiedKFold(n_splits=N, shuffle=True, )\n",
        "    \n",
        "    for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
        "        pipeline.fit(X[train_index], y[train_index])\n",
        "        preds = pipeline.predict(X[test_index])\n",
        "\n",
        "        fold_metrics[f'f1_{i}'] = f1_score(y[test_index], preds, labels=labels, average=None)\n",
        "\n",
        "    result = pd.DataFrame(index=labels)\n",
        "    result['f1'] = fold_metrics[[f'f1_{i}' for i in range(N)]].mean(axis=1).round(2)\n",
        "    result.loc['mean'] = result.mean().round(2)\n",
        "    \n",
        "    return result.loc['mean']['f1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "a892e64a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Вопрос:\n",
        "# Можно ли избавиться от повторногой векторизации в pipeline,\n",
        "# а то получается, что я постоянно трачу по 3 минуты только на это,\n",
        "# когда сам классификатор работает за секунды... Либо я чего-то не понимаю...\n",
        "\n",
        "pipeline_SVD_RF = Pipeline([\n",
        "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), min_df=3, max_df=0.3)),\n",
        "    ('decomposition', TruncatedSVD(100)),\n",
        "    ('clf', RandomForestClassifier(n_estimators=100, max_depth=6))\n",
        "])\n",
        "\n",
        "pipeline_SVD_ExtraTrees = Pipeline([\n",
        "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), min_df=3, max_df=0.3)),\n",
        "    ('decomposition', TruncatedSVD(100)),\n",
        "    ('clf', ExtraTreesClassifier(n_estimators=100, max_depth=6))\n",
        "])\n",
        "\n",
        "pipeline_SVD_SGD = Pipeline([\n",
        "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), min_df=3, max_df=0.3)),\n",
        "    ('decomposition', TruncatedSVD(100)),\n",
        "    ('clf', SGDClassifier(max_iter=1000, tol=1e-3))\n",
        "])\n",
        "\n",
        "pipeline_SVD_KN = Pipeline([\n",
        "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), min_df=3, max_df=0.3)),\n",
        "    ('decomposition', TruncatedSVD(100)),\n",
        "    ('clf', KNeighborsClassifier(n_neighbors=3))\n",
        "])\n",
        "\n",
        "pipeline_NMF_RF = Pipeline([\n",
        "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), min_df=3, max_df=0.3)),\n",
        "    ('decomposition', NMF(100)),\n",
        "    ('clf', RandomForestClassifier(n_estimators=100, max_depth=6))\n",
        "])\n",
        "\n",
        "pipeline_NMF_ExtraTrees = Pipeline([\n",
        "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), min_df=3, max_df=0.3)),\n",
        "    ('decomposition', NMF(100)),\n",
        "    ('clf', ExtraTreesClassifier(n_estimators=100, max_depth=6))\n",
        "])\n",
        "\n",
        "pipeline_NMF_SGD = Pipeline([\n",
        "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), min_df=3, max_df=0.3)),\n",
        "    ('decomposition', NMF(100)),\n",
        "    ('clf', SGDClassifier(max_iter=1000, tol=1e-3))\n",
        "])\n",
        "\n",
        "pipeline_NMF_KN = Pipeline([\n",
        "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), min_df=3, max_df=0.3)),\n",
        "    ('decomposition', NMF(100)),\n",
        "    ('clf', KNeighborsClassifier(n_neighbors=3))\n",
        "])\n",
        "\n",
        "pipeline_LDA_RF = Pipeline([\n",
        "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), min_df=3, max_df=0.3)),\n",
        "    ('decomposition', LatentDirichletAllocation(100)),\n",
        "    ('clf', RandomForestClassifier(n_estimators=100, max_depth=6))\n",
        "])\n",
        "\n",
        "pipeline_LDA_ExtraTrees = Pipeline([\n",
        "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), min_df=3, max_df=0.3)),\n",
        "    ('decomposition', LatentDirichletAllocation(100)),\n",
        "    ('clf', ExtraTreesClassifier(n_estimators=100, max_depth=6))\n",
        "])\n",
        "\n",
        "pipeline_LDA_SGD = Pipeline([\n",
        "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), min_df=3, max_df=0.3)),\n",
        "    ('decomposition', LatentDirichletAllocation(100)),\n",
        "    ('clf', SGDClassifier(max_iter=1000, tol=1e-3))\n",
        "])\n",
        "\n",
        "pipeline_LDA_KN = Pipeline([\n",
        "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), min_df=3, max_df=0.3)),\n",
        "    ('decomposition', LatentDirichletAllocation(100)),\n",
        "    ('clf', KNeighborsClassifier(n_neighbors=3))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "ad2c19f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "NMF_RF = eval_table(data['description_norm'], data['category_name'], pipeline_NMF_RF)\n",
        "NMF_SGD = eval_table(data['description_norm'], data['category_name'], pipeline_NMF_SGD)\n",
        "NMF_ExtraTrees = eval_table(data['description_norm'], data['category_name'], pipeline_NMF_ExtraTrees)\n",
        "NMF_KN = eval_table(data['description_norm'], data['category_name'], pipeline_NMF_KN)\n",
        "\n",
        "SVD_RF = eval_table(data['description_norm'], data['category_name'], pipeline_SVD_RF)\n",
        "SVD_SGD = eval_table(data['description_norm'], data['category_name'], pipeline_SVD_SGD)\n",
        "SVD_ExtraTrees = eval_table(data['description_norm'], data['category_name'], pipeline_SVD_ExtraTrees)\n",
        "SVD_KN = eval_table(data['description_norm'], data['category_name'], pipeline_SVD_KN)\n",
        "\n",
        "LDA_RF = eval_table(data['description_norm'], data['category_name'], pipeline_LDA_RF)\n",
        "LDA_SGD = eval_table(data['description_norm'], data['category_name'], pipeline_LDA_SGD)\n",
        "LDA_ExtraTrees = eval_table(data['description_norm'], data['category_name'], pipeline_LDA_ExtraTrees)\n",
        "LDA_KN = eval_table(data['description_norm'], data['category_name'], pipeline_LDA_KN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "8cb55baf",
      "metadata": {},
      "outputs": [],
      "source": [
        "res_NMF = {'NMF_RF': NMF_RF, 'NMF_SGD': NMF_SGD, 'NMF_ExtraTrees': NMF_ExtraTrees, 'NMF_KN': NMF_KN}\n",
        "NMF_DF = pd.DataFrame.from_dict(res_NMF, orient='index', columns=['F1-mean'])\n",
        "\n",
        "res_SVD = {'SVD_RF': SVD_RF, 'SVD_SGD': SVD_SGD, 'SVD_ExtraTrees': SVD_ExtraTrees, 'SVD_KN': SVD_KN}\n",
        "SVD_DF = pd.DataFrame.from_dict(res_SVD, orient='index', columns=['F1-mean'])\n",
        "\n",
        "res_LDA = {'LDA_RF': LDA_RF, 'LDA_SGD': LDA_SGD, 'LDA_ExtraTrees': LDA_ExtraTrees, 'LDA_KN': LDA_KN}\n",
        "LDA_DF = pd.DataFrame.from_dict(res_LDA, orient='index', columns=['F1-mean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "b846a2df",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1-mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVD_ExtraTrees</th>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NMF_ExtraTrees</th>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LDA_ExtraTrees</th>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVD_RF</th>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LDA_RF</th>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NMF_KN</th>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NMF_RF</th>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVD_KN</th>\n",
              "      <td>0.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NMF_SGD</th>\n",
              "      <td>0.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LDA_KN</th>\n",
              "      <td>0.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LDA_SGD</th>\n",
              "      <td>0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVD_SGD</th>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                F1-mean\n",
              "SVD_ExtraTrees     0.21\n",
              "NMF_ExtraTrees     0.26\n",
              "LDA_ExtraTrees     0.36\n",
              "SVD_RF             0.42\n",
              "LDA_RF             0.42\n",
              "NMF_KN             0.43\n",
              "NMF_RF             0.45\n",
              "SVD_KN             0.46\n",
              "NMF_SGD            0.51\n",
              "LDA_KN             0.51\n",
              "LDA_SGD            0.59\n",
              "SVD_SGD            0.66"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.concat([NMF_DF, SVD_DF, LDA_DF]).sort_values('F1-mean', ascending=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

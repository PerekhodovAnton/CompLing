{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00fad453",
      "metadata": {
        "id": "00fad453"
      },
      "source": [
        "# Домашнее задание № 4. Языковые модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d056af4",
      "metadata": {
        "id": "5d056af4"
      },
      "source": [
        "## Задание 1 (8 баллов)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f532a8",
      "metadata": {
        "id": "d1f532a8"
      },
      "source": [
        "В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de743d1d",
      "metadata": {
        "id": "de743d1d"
      },
      "source": [
        "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
        "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели.\n",
        "Можно использовать данные из семинара или любые другие (можно брать только часть текста, если считается слишком долго). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
        "\n",
        "\n",
        "Подсказки:  \n",
        "    - нужно будет добавить еще один тэг \\<start>  \n",
        "    - можете использовать тот же подход с матрицей вероятностей, но по строкам хронить биграмы, а по колонкам униграммы\n",
        "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так)\n",
        "    - у вас будут словари с индексами биграммов и униграммов, не перепутайте их при переводе индекса в слово - словарь биграммов будет больше словаря униграммов и все индексы из униграммного словаря будут формально подходить для словаря биграммов (не будет ошибки при id2bigram[unigram_id]), но маппинг при этом будет совершенно неправильным"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d078056d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d078056d",
        "outputId": "02341d85-7272-48bb-f0db-3d350639baa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install razdel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "id": "6afcef88",
      "metadata": {
        "id": "6afcef88"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "from razdel import sentenize\n",
        "from razdel import tokenize as razdel_tokenize\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML\n",
        "from scipy.sparse import lil_matrix, csr_matrix, csc_matrix\n",
        "from collections import Counter\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news = open('lenta.txt').read()"
      ],
      "metadata": {
        "id": "BqTsZqWa9Cag"
      },
      "id": "BqTsZqWa9Cag",
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(text):\n",
        "    normalized_text = [word.text.strip(punctuation) for word \\\n",
        "                                                            in razdel_tokenize(text)]\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
        "    return normalized_text\n",
        "\n",
        "def trigrammer(tokens, n=3):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams\n",
        "\n",
        "def bigrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i +n]))\n",
        "    return ngrams"
      ],
      "metadata": {
        "id": "4kcrGQEw9cNA"
      },
      "id": "4kcrGQEw9cNA",
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_news = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(news[:5000000])]"
      ],
      "metadata": {
        "id": "x5GBjr1VRY-k"
      },
      "id": "x5GBjr1VRY-k",
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigrams_news = Counter()\n",
        "bigrams_news = Counter()\n",
        "trigrams_news = Counter()\n",
        "\n",
        "for sentence in sentences_news:\n",
        "    unigrams_news.update(sentence)\n",
        "    trigrams_news.update(trigrammer(sentence))\n",
        "    bigrams_news.update(bigrammer(sentence))"
      ],
      "metadata": {
        "id": "xQjsNqk29x4s"
      },
      "id": "xQjsNqk29x4s",
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_news = lil_matrix((len(bigrams_news),\n",
        "                        len(unigrams_news)))\n",
        "\n",
        "id2word_news = list(unigrams_news)\n",
        "word2id_news = {word:i for i, word in enumerate(id2word_news)}\n",
        "\n",
        "id2bigram_news = list(bigrams_news)\n",
        "bigram2id_news = {word:i for i, word in enumerate(bigrams_news)}\n",
        "\n",
        "\n",
        "for ngram in trigrams_news:\n",
        "    word1, word2, word3 = ngram.split()\n",
        "    bigram = word1 + ' ' + word2\n",
        "    matrix_news[bigram2id_news[bigram], word2id_news[word3]] =  (trigrams_news[ngram]/\n",
        "                                                                     bigrams_news[bigram])"
      ],
      "metadata": {
        "id": "1O8szUrrSCxs"
      },
      "id": "1O8szUrrSCxs",
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(matrix, id2word, bigram2id, n=100, start='<start> <start>'):\n",
        "    text = []\n",
        "    current = start\n",
        "\n",
        "    for i in range(n):\n",
        "        bigram_id = bigram2id[current]\n",
        "        chosen_word_idx = np.random.choice(matrix.shape[1], p=matrix[bigram_id].toarray()[0])\n",
        "        word = id2word[chosen_word_idx]\n",
        "        text.append(word)\n",
        "        # строку ниже надо было перенести сюда относительно кода из семинара, иначе была ошибка по вероятностям\n",
        "        current = current.split()[1] + ' ' + word\n",
        "\n",
        "        if word == '<end>':\n",
        "            current = '<start> <start>'\n",
        "    return ' '.join(text)"
      ],
      "metadata": {
        "id": "DBOVxd9J-fTV"
      },
      "id": "DBOVxd9J-fTV",
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate(matrix_news, id2word_news, bigram2id_news).replace('<end>', '\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDDPku2cW6uA",
        "outputId": "a95c1620-1aa6-4df7-ad0e-6bb5e2176959"
      },
      "id": "LDDPku2cW6uA",
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "правительственная комиссия во главе с генералом пришли солдаты и офицеры подразделения армии ветераны войны представители штаба подчеркнули что их будет лариса кривцова с 7.40 до 8.00 ежедневно \n",
            " русская версия odigo интегрирована с поисковой системой rambler заглавная страница которой является general tire северная каролина \n",
            " напомним что в 1999 году после победы лейбористской партии министр образования россии филиппов академик-секретарь отделения литературы и языка российской академии наук армении депутат микаел котанян \n",
            " по словам министра руководство страны пойдет на выборах в марте прошлого года и шестого по значимости уровня падения за день сгорает 300 тонн муки учебники медикаменты и необходимая техника\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate(matrix_news, id2word_news, bigram2id_news).replace('<end>', '\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCxKlzewqZK0",
        "outputId": "51b6c00e-ab4b-4aed-cecb-bbaff73432d9"
      },
      "id": "UCxKlzewqZK0",
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "все мы хотим об этом корр \n",
            " были воссозданы цветные витражи станции новослободская арочные фрески станции киевская на эскалаторах французские дизайнеры воссоздали светильники станции университет \n",
            " новый автомат еще не могут оправдать удары по боевикам и российским властям \n",
            " в церемонии прощания приняли участие 1500 человек \n",
            " как сообщает агентство прайм-тасс \n",
            " в этой тюрьме под контроль но осталась напряженной утром 6 октября объявили о самороспуске \n",
            " по данным некоторых экспертов днем рождения \n",
            " говорят что им удастся сделать чип передающий хотя бы часть денег развивая сотрудничество с фирмами собственниками которых являются люди чьи имена содержатся в списке потенциальных неудачников\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate(matrix_news, id2word_news, bigram2id_news).replace('<end>', '\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTjEwBSUqbJQ",
        "outputId": "fa5b6163-8334-4365-8717-5182bd0a6ecc"
      },
      "id": "WTjEwBSUqbJQ",
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "кроме того офер нимроди входит в систему слишком много желающих встретиться с президентом рф власти ижевска предложили ввести в заблуждение с помощью специально обученных собак которые будут готовы выложить круглую сумму за вычетом затрат на производство самодельные взрывные устройства \n",
            " предполагается что президент клинтон отправил в отставку премьер-минстра страны массимо д алемы были найдены в кассовом зале вокзала \n",
            " исходя из их суммарной величины 1 декабря в белгард министр обороны филиппин орландо меркардо сообщил журналистам министр сельского хозяйства курс молдавского лея остается стабильным ставки по ним было реализовано 87 тысяч транзакций проведенных через эти счета подорвали репутацию службы \n",
            " всего\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(logp, N):\n",
        "    return np.exp((-1/N) * logp)\n",
        "\n",
        "\n",
        "def compute_join_trigram(text, bigram_counts, trigram_counts):\n",
        "    prob = 0\n",
        "    tokens = normalize(text)\n",
        "    for ngram in trigrammer(['<start>', '<start>'] + tokens + ['<end>']):\n",
        "        word1, word2, word3 = ngram.split()\n",
        "        bigram = word1 + ' ' + word2\n",
        "        if bigram in bigram_counts and ngram in trigram_counts:\n",
        "            prob += np.log(trigram_counts[ngram]/bigram_counts[bigram])\n",
        "        else:\n",
        "            prob += np.log(2e-5)\n",
        "\n",
        "    return prob, len(tokens)"
      ],
      "metadata": {
        "id": "ohjHLnZTrExE"
      },
      "id": "ohjHLnZTrExE",
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = 'Спешу сообщить, что на Манежной площади открылась главная Рождественская ярмарка Петербурга. \\\n",
        "В волшебном городе \"Конфетобурге\" каждый посетитель найдет занятие по душе — здесь можно прокатиться на аттракционах, \\\n",
        "посетить ремесленные и кулинарные мастер-классы и, конечно же, встретиться с Дедом Морозом. \\\n",
        "Самых маленьких гостей ждут двухъярусная карусель, каток и паровозик\", — написал он.'\n",
        "log_prob, N = compute_join_trigram(phrase, bigrams_news, trigrams_news)\n",
        "perplexity(log_prob, N)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6I0PbJwro6O",
        "outputId": "dbd7df90-5d62-4d8f-f6a7-779509b6718a"
      },
      "id": "F6I0PbJwro6O",
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000.00000000027"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = 'Гуляния на Московской площади пройдут с 22 декабря по 8 января. Тематикой новой площадки станут сказки \\\n",
        "Александра Сергеевича Пушкина. Здесь ожидается культурно-образовательная программа для гостей, а также зимние игры и развлечения. По традиции также можно будет приобрести новогодние сувениры и сладости.'\n",
        "log_prob, N = compute_join_trigram(phrase, bigrams_news, trigrams_news)\n",
        "perplexity(log_prob, N)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urm8r_FBtuXG",
        "outputId": "23435e36-f6c2-4a28-bd6a-edf922a98b22"
      },
      "id": "Urm8r_FBtuXG",
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53089.03380543496"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = '\"В определенную службу оператора приходят запросы от департамента по чрезвычайным ситуациям, \\\n",
        "который информирует жителей различных регионов об изменениях в погодных условиях. <…> Отправителем данных является 112, \\\n",
        "мы выступаем как инструмент передачи сообщений. В данном конкретном случае произошла техническая ошибка. В рассылке значок \\\n",
        "градуса (°) был заменен на ноль. После обнаружения некорректной цифры всем абонентам региона, \\\n",
        "куда пришли сильные морозы, было отправлено исправленное сообщение\", — пояснили в компании.'\n",
        "log_prob, N = compute_join_trigram(phrase, bigrams_news, trigrams_news)\n",
        "perplexity(log_prob, N)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZiedYkXtzVy",
        "outputId": "8d3cf588-a9d4-4947-8329-1b1648da33fb"
      },
      "id": "6ZiedYkXtzVy",
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33261.04571676868"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}